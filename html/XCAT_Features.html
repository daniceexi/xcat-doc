<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
</head>
<body>
<div id="TOC">
<ul>
<li><a href="#xcat-2-features-and-supported-hwos">xCAT 2 Features and Supported HW/OS</a><ul>
<li><a href="#highlights">Highlights</a></li>
<li><a href="#os-support">OS Support</a></li>
<li><a href="#hardware-support">Hardware Support</a></li>
<li><a href="#hardware-control-features">Hardware Control Features</a></li>
<li><a href="#additional-features">Additional Features</a></li>
</ul></li>
</ul>
</div>
<p><!-- START doctoc generated TOC please keep comment here to allow auto update --> <!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE --> Table of Contents</p>
<ul>
<li><a href="#xcat-2-features-and-supported-hwos">xCAT 2 Features and Supported HW/OS</a></li>
<li><a href="#highlights">Highlights</a></li>
<li><a href="#os-support">OS Support</a></li>
<li><a href="#hardware-support">Hardware Support</a></li>
<li><a href="#hardware-control-features">Hardware Control Features</a></li>
<li><a href="#additional-features">Additional Features</a></li>
</ul>
<!-- END doctoc generated TOC please keep comment here to allow auto update -->

<p>[[img src=Official-xcat-doc.png]]</p>
<h1 id="xcat-2-features-and-supported-hwos"><a href="#TOC">xCAT 2 Features and Supported HW/OS</a></h1>
<p>xCAT 2 is not an evolution or a rewrite of xCAT 1.x. xCAT 2 is a revolutionary new project created by the best cluster management developers at IBM. This team consists of IBM CSM, xCAT 1.x, System x, System p, e1350, and iDataPlex developers.</p>
<h2 id="highlights"><a href="#TOC">Highlights</a></h2>
<ul>
<li>Client/server architecture. Clients can run on any Perl compliant system (including Windows). All communications are SSL encrypted.</li>
<li>Role-based administration. Different users can be assigned various administrative roles for different resources.</li>
<li>Stateless,statelite and iSCSI support. Stateless can be RAM-root, compressed RAM-root, or stacked NFS-root. Linux software initiator iSCSI support for RH and SLES included. Systems without hardware-based initiators can still be iSCSI installed and booted.</li>
<li>Windows support: imagex, rinstall, and iSCSI.</li>
<li>Kvm and VMWare full virtualized support, including the rmigrate command to request live migration of a virtualized guest from one host to another.</li>
<li>Scalability. xCAT 2.x was designed to scale beyond your budget. 100,000 nodes? No problem with xCAT's Hierarchical Management Cloud (HMC). A single A Management node may have any number of service nodes to increase the provisioning throughput and management of the largest clusters. All cluster services such as LDAP, DNS, DHCP, NTP, Syslog, etc... are configured to use the Hierarchical Management Cloud. Outbound cluster management commands (e.g. rpower, xdsh, xdcp, etc...) utilize this hierarchy for scalable systems management.</li>
<li><a href="Node_Discovery">Automagic discovery</a>. Single power button press, physical location based, discovery and configuration capability. &quot;Any sufficiently advanced technology is indistinguishable from magic.&quot; -- Arthur C. Clark.</li>
<li>Choice of database backend: SQLite, Postgresql, MySQL, DB2.</li>
<li>Plug-in architecture for compartmental development. Add your own xCAT functionally to do what ever you want. New plug-ins extend the xCAT vocabulary available to xCAT clients.</li>
<li>Monitoring plug-in infrastructure to easily integrate 3rd party monitoring software into xCAT cluster. Plug-ins provided with xCAT: SNMP, RMC, Ganglia, Performance Copilot (more in future)</li>
<li>Notification infrastructure to be able to watch for xCAT DB table changes.</li>
<li>SNMP monitoring. Trap handler handles all SNMP traps.</li>
<li>Node status update (nodelist.status is updated during the node deployment node power on/off and updatenode processing).</li>
<li>Centralized console and systems logs.</li>
<li>Software/firmware inventory command to detect variance between nodes. Software inventory for images too.</li>
<li>Automatic installation of any additional rpms requested by the user during node deployment phase and after the nodes are up and running.</li>
<li>Documentation: online wiki, pdfs, complete man pages, database table documentation</li>
<li>Eclipse Public License.</li>
</ul>
<h2 id="os-support"><a href="#TOC">OS Support</a></h2>
<p>Note: the list of supported distros is constantly changing, but here's what's supported as of 10/3/2013.</p>
<p>The supported OS's vary depending on the node provisioning method...</p>
<ul>
<li>Traditional local disk and SAN provisioning using native deployment methods (kickstart, etc.):
<ul>
<li>SLES10 SP2 or higher, SLES 11 SPx, SLES 12, RHEL 5.x &amp; 6.x, CentOS 5.x &amp; 6.x, SL 5.x &amp; 6.x, Fedora 8-19, Ubuntu 12.04 &amp; 13.04, AIX 6.1, 7.1 (all available Technology Levels), Windows 2008-2012, Windows 7</li>
</ul></li>
<li>Stateless (RAM-root diskless):
<ul>
<li>All of the OS's listed above in the traditional diskful provisioning, <strong>except</strong>: SLES12, AIX and Windows</li>
</ul></li>
<li>Statelite (NFS-root diskless):
<ul>
<li>All of the OS's listed above for stateless, <strong>plus</strong> AIX 6.1, 7.1 (all available Technology Levels), but <strong>not</strong> Ubuntu</li>
</ul></li>
<li>Stateful diskless using iSCSI:
<ul>
<li>All of the versions listed above for SLES, RHEL/CentOS/Fedora, and Windows</li>
</ul></li>
<li>Imaging (cloning):
<ul>
<li>RHEL 6 and SLES 11 SP2 &amp; SP3, AIX 6.1, 7.1 (all available Technology Levels), Windows 2008</li>
</ul></li>
<li>Note: AIX 5.3 is no longer supported in xCAT 2.5 and above.</li>
</ul>
<h2 id="hardware-support"><a href="#TOC">Hardware Support</a></h2>
<p>Here's what's supported as of 03/15/2013:</p>
<ul>
<li>All IBM Bladecenter and System x hw that is part of the IBM Intelligent Cluster</li>
<li>All iDataplex hw</li>
<li>All IBM Flex hw</li>
<li>Most IPMI-controlled x86_64 machines, if not IBM/Lenovo we need to work with you.</li>
<li>All System p hardware</li>
<li>All System z hardware running zVM</li>
</ul>
<h2 id="hardware-control-features"><a href="#TOC">Hardware Control Features</a></h2>
<ul>
<li>Power control</li>
<li>Boot device control (full boot sequence on Bladecenter, next boot device on other systems)</li>
<li>Sensor readings (Temperature, Fan speed, Voltage, Current, and fault indicators as supported by systems)</li>
<li>Collection of MAC addresses</li>
<li>Event logs</li>
<li>LED status/modification (identify LED on all systems, diagnostic LEDs on select IBM rack mount servers)</li>
<li>Serial-over-LAN (SOL)</li>
<li>Service processor configuration.</li>
<li>Hardware control point discovery using SLP (MM, HMC, FSP)</li>
<li>Virtual partition creation</li>
</ul>
<h2 id="additional-features"><a href="#TOC">Additional Features</a></h2>
<ul>
<li>CLI mode, scripts, simple text based config files</li>
<li>Uses perl primarily</li>
<li>xcat installed linux nodes are identical to kickstart or autoyast installed nodes, wrt RPMs, etc. Nothing is altered from the distro (eg: Rocks switched from /etc/passwd to 411 for authentication), we use stock kernels. So, if commercial support is critical, xcat has a better story.</li>
<li>Multiple distros: AIX,SLES, OpenSUSE, RHEL, CentOS, SL, FC, Windows via imaging is supported. You can even have mixed OSs in a single cluster with certain limitations.</li>
<li>Works well with any x86/x86_64 server (even non-IBM servers).</li>
<li>IBM Bladecenter and iDataPlex are fully supported</li>
<li>Custom extensions need only minimal effort: eg adding a new distro.</li>
<li>PBS, GPFS, Myrinet installations are supported</li>
<li>Postscripts - Post installation scripts supported for both diskful and diskfree environments.</li>
</ul>
</body>
</html>
